---
layout: default_ak
title: About Me
root: ""
---

<div class="container" >
	<div id="leftbox" >
		<p><img src="images/me.jpg" alt="Hello There!" width="200" />
		Department of Statistical Science <br/>
		Duke University <br/>
		214 Old Chemistry <br/>
		P.O. Box 90251 <br/>
    Durham, NC 27708-0251 <br/>
		<a href="mailto:MYNICKNAME@stat.duke.edu">MYNICKNAME@stat.duke.edu</a>
		</p>
	</div>
	<div id="rightbox">

<p>I am an Assistant Professor of the Department of Statistical Science at Duke University
and affiliated faculty in Computer Science, Biostaitics and Bioinformatics, the information
initiative at Duke (iiD), and the Social Science Research Institute. I also hold a Schedule A 
appointment at the U.S. Census Bureau.
</p>

<h3> Entity Resolution </h3>


<p>
  My main research focus is on entity resolution (record linkage or de-duplication), where the goal is to remove duplicated information from large, noisy databases in the absence of unique identifiers. In my research, I develop flexible methods for entity resolution that are able to handle the uncertainty of the record linkage process and can be easily integrated with post-linkage statistical analyses, such as logistic regression or capture recapture. In addition, a strength of the methods I propose, is that they are able to maintain low error rates (precision and recall) and beat the state-of-the-art methods in the literature in terms of these error rates. Furthermore, I have developed the first performance bounds for a general class of entity resolution models, illustrating when the bounds hold in practice. I proposed a new methodology for entity resolution, realizing that the size of the clusters grows sub-linearly compared to the number of records, which contrasts with many other processes. In turn, this had led to proposing a general class of models for clustering of tasks with a sub-linear growth that are scalable, and illustrating their success for entity resolution.
</p>

<h3>Other Research </h3>

<p>
In addition to approaching entity resolution from a Bayesian perspecitive, I also approach it using statistical machine learning. Specifically, I have been able to leverage locality sensitive hashing (LSH) as a diminsion reduction technique for entity resolution and develop fast ways of estimating the unique number of clusters in very large databases. In addition, we have shown that our methods have nice theoretical properties and are very scalable. 
</p>

<h3>Research Group </h3>

<p>
If you're interested in working with me as a MS or PhD student, please set up a time to talk to me with email
after looking over my research page and looking over some recent work that myself and my group has done. 
</p>

<h3>Machine Learning </h3>

<p>
I am heavily involved in integrating computation into both the graduate and 
undergraduate statistics curriculum, using reproducible 
research and also using real and complex data sets. All of my courses that
are taught at Duke can be found at github. In addition, I have taught the first course in
Statistical Science in machine learning for undergraduates, and I'm working with students so that machine learning can have a greater presence on campus through the Youth in Machine Learning (YiML) program, which consists of a Machine Learning workshop, ML Bytes lecture series, and bootcamps for undergraduate students. 
</p>

	</div>
</div>
